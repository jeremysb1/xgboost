{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ircKf0sf5ZQg_qsWtpvo3FpvSFM-ve6a",
      "authorship_tag": "ABX9TyO6RZGQucVT1Qizy82NFEkR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeremysb1/xgboost/blob/main/best_practices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B1lTLkA0aNmq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/XGBoost/AB_NYC_2019.csv\")\n",
        "excluding_list = ['price', 'id', 'latitude', 'longitude', 'host_id',\n",
        "                  'last_review', 'name', 'host_name']\n",
        "low_card_categorical = ['neighbourhood_group', 'room_type']\n",
        "high_card_categorical = ['neighbourhood']\n",
        "continuous = ['minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
        "              'calculated_host_listings_count', 'availability_365']\n",
        "target_mean = (data[\"price\"] > data[\"price\"].mean()).astype(int)\n",
        "target_median = (data[\"price\"] > data[\"price\"].median()).astype(int)\n",
        "target_multiclass = pd.qcut(data[\"price\"], q=5, labels=False)\n",
        "target_regression = data[\"price\"]\n",
        "categorical_onehot_encoding = OneHotEncoder(handle_unknown='ignore')\n",
        "categorical_ord_encoding = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=np.nan)\n",
        "numeric_standardization = Pipeline([('StandardScaler', StandardScaler()),\n",
        "                                    ('Imputer', SimpleImputer(strategy=\"constant\", fill_value=0))])\n",
        "\n",
        "column_transform = ColumnTransformer(\n",
        "    [('low_card_categories', categorical_onehot_encoding, low_card_categorical),\n",
        "     ('high_card_categories', categorical_ord_encoding, high_card_categorical),\n",
        "     ('numeric', numeric_standardization, continuous)],\n",
        "    remainder='drop',\n",
        "    verbose_feature_names_out=True,\n",
        "    sparse_threshold=0.0)\n",
        "\n",
        "lm_column_transform = ColumnTransformer(\n",
        "    [('low_card_categories', categorical_onehot_encoding, low_card_categorical),\n",
        "     ('numeric', numeric_standardization, continuous)],\n",
        "    remainder='drop',\n",
        "    verbose_feature_names_out=True,\n",
        "    sparse_threshold=0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multivariate missing data imputation"
      ],
      "metadata": {
        "id": "4k3Kg89Xav-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multivariate imputation:"
      ],
      "metadata": {
        "id": "0c1wMxFvdwYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "Xm = data[continuous].copy()\n",
        "missing_percentage = 0.05\n",
        "np.random.seed(0)\n",
        "mask = np.random.rand(*Xm.shape) < missing_percentage\n",
        "Xm[mask] = np.nan\n",
        "\n",
        "simple_imputer = SimpleImputer()\n",
        "Xm_si = simple_imputer.fit_transform(Xm)\n",
        "\n",
        "rf = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
        "multivariate_imputer = IterativeImputer(estimator=rf, max_iter=1, tol=0.01)\n",
        "Xm_mi = multivariate_imputer.fit_transform(Xm)\n",
        "\n",
        "mae = pd.DataFrame({\"simple\": np.mean(np.abs(data[continuous] - Xm_si), axis=0),\n",
        "                    \"multivariate\": np.mean(np.abs(data[continuous] - Xm_mi), axis=0)},\n",
        "                   index = continuous)\n",
        "\n",
        "print(mae)"
      ],
      "metadata": {
        "id": "xWxucfDpctg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a97e29-1239-43d8-96a7-7077ed66069c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  simple  multivariate\n",
            "minimum_nights                  0.347355      0.260156\n",
            "number_of_reviews               1.327776      0.858506\n",
            "reviews_per_month               0.057980      0.036876\n",
            "calculated_host_listings_count  0.579423      0.368567\n",
            "availability_365                6.025748      4.622640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target Encoding"
      ],
      "metadata": {
        "id": "6Z0Zm0tAIh6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a high cardinality categorical feature:"
      ],
      "metadata": {
        "id": "34J4XLUTI57v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_2_cat(feature, bins=100):\n",
        "    min_value = feature.min()\n",
        "    bin_size = (feature.max() - min_value) / bins\n",
        "    return ((feature - min_value) / bin_size).astype(int)\n",
        "\n",
        "data['coordinates'] = bin_2_cat(data['latitude']) * 1000 + bin_2_cat(data['longitude'])\n",
        "high_card_categorical += ['coordinates']\n",
        "\n",
        "print(data[high_card_categorical].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj1dQt6VI9KM",
        "outputId": "6bd26d21-6357-4f14-b59a-61a2a048c2f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neighbourhood     221\n",
            "coordinates      2259\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using target encoding in the pipeline:"
      ],
      "metadata": {
        "id": "au8HhQGOKjMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkx_mEMEe_ab",
        "outputId": "e5b9204c-9548-4efb-e320-44639bfee558"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m995.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from category_encoders.target_encoder import TargetEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "from sklearn.metrics import accuracy_score, make_scorer\n",
        "\n",
        "target_encoder = TargetEncoder(cols=high_card_categorical, smoothing=0.5)\n",
        "\n",
        "accuracy = make_scorer(accuracy_score)\n",
        "cv = KFold(5, shuffle=True, random_state=0)\n",
        "xgb = XGBClassifier(booster = 'gbtree',\n",
        "                    objective='reg:logistic',\n",
        "                    n_estimators=300,\n",
        "                    max_depth=4,\n",
        "                    min_child_weight=3)\n",
        "\n",
        "column_transform = ColumnTransformer(\n",
        "    [('low_card_categories', categorical_onehot_encoding, low_card_categorical),\n",
        "     ('high_card_categories', target_encoder, high_card_categorical),\n",
        "     ('numeric', numeric_standardization, continuous)],\n",
        "    remainder='drop',\n",
        "    verbose_feature_names_out=True,\n",
        "    sparse_threshold=0.0)\n",
        "\n",
        "model_pipeline = Pipeline([('processing', column_transform),\n",
        "                        ('xgb', xgb)])\n",
        "\n",
        "cv_scores = cross_validate(estimator = model_pipeline,\n",
        "                           X= data,\n",
        "                           y = target_median,\n",
        "                           scoring=accuracy,\n",
        "                           cv=cv,\n",
        "                           return_train_score=True,\n",
        "                           return_estimator=True)\n",
        "\n",
        "mean_cv = np.mean(cv_scores['test_score'])\n",
        "std_cv = np.std(cv_scores['test_score'])\n",
        "fit_time = np.mean(cv_scores['fit_time'])\n",
        "score_time = np.mean(cv_scores['score_time'])\n",
        "\n",
        "print(f\"{mean_cv:0.3f} ({std_cv:0.3f})\",\n",
        "      f\"fit: {fit_time:0.2f} secs pred: {score_time:0.2f} secs\")"
      ],
      "metadata": {
        "id": "C9f4vP--KkLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a257d7c-f9a1-4ffe-d78f-111d1e51a59d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.840 (0.002) fit: 5.26 secs pred: 0.08 secs\n"
          ]
        }
      ]
    }
  ]
}